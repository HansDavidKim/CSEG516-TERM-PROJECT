# ğŸ³ Docker ì‚¬ìš© ê°€ì´ë“œ

RLB-MI ê³µê²©ì„ Docker í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

## ğŸ“‹ ì‚¬ì „ ìš”êµ¬ì‚¬í•­

### CPU ë²„ì „
- Docker ì„¤ì¹˜
- ìµœì†Œ 8GB RAM ê¶Œì¥

### GPU ë²„ì „
- Docker ì„¤ì¹˜
- NVIDIA GPU
- [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html) ì„¤ì¹˜
- CUDA í˜¸í™˜ GPU

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ë°©ë²• 1: Docker Compose ì‚¬ìš© (ê¶Œì¥)

#### CPU ë²„ì „
```bash
# ë¹Œë“œ ë° ì‹¤í–‰
docker-compose --profile cpu up -d rlb-mi-cpu

# ì»¨í…Œì´ë„ˆ ì ‘ì†
docker-compose exec rlb-mi-cpu bash

# ë˜ëŠ” í•œ ë²ˆì—
docker-compose --profile cpu run --rm rlb-mi-cpu bash
```

#### GPU ë²„ì „
```bash
# ë¹Œë“œ ë° ì‹¤í–‰
docker-compose --profile gpu up -d rlb-mi-gpu

# ì»¨í…Œì´ë„ˆ ì ‘ì†
docker-compose exec rlb-mi-gpu bash

# ë˜ëŠ” í•œ ë²ˆì—
docker-compose --profile gpu run --rm rlb-mi-gpu bash
```

### ë°©ë²• 2: Docker ëª…ë ¹ì–´ ì§ì ‘ ì‚¬ìš©

#### CPU ë²„ì „
```bash
# ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t rlb-mi:cpu -f Dockerfile .

# ì»¨í…Œì´ë„ˆ ì‹¤í–‰ (ì¸í„°ë™í‹°ë¸Œ)
docker run -it --rm \
  -v $(pwd)/checkpoints:/app/checkpoints \
  -v $(pwd)/attack_results:/app/attack_results \
  -v $(pwd)/dataset:/app/dataset \
  rlb-mi:cpu bash
```

#### GPU ë²„ì „
```bash
# ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t rlb-mi:gpu -f Dockerfile.gpu .

# ì»¨í…Œì´ë„ˆ ì‹¤í–‰ (GPU ì‚¬ìš©)
docker run -it --rm \
  --gpus all \
  -v $(pwd)/checkpoints:/app/checkpoints \
  -v $(pwd)/attack_results:/app/attack_results \
  -v $(pwd)/dataset:/app/dataset \
  rlb-mi:gpu bash
```

## ğŸ“š ì‚¬ìš© ì˜ˆì‹œ

### 1. ë°ì´í„° ì¤€ë¹„ (í˜¸ìŠ¤íŠ¸ì—ì„œ)

```bash
# ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p checkpoints attack_results dataset pretrained

# í•„ìš”í•œ íŒŒì¼ë“¤ ë°°ì¹˜
# - checkpoints/generator_last.pt
# - checkpoints/vgg16_celeba_best.pt
# - dataset/... (ì˜µì…˜)
```

### 2. ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ ê³µê²© ì‹¤í–‰

```bash
# ì»¨í…Œì´ë„ˆ ì ‘ì† í›„
python main.py run-rlb-mi-attack \
  --generator checkpoints/generator_last.pt \
  --target-model checkpoints/vgg16_celeba_best.pt \
  --model-name VGG16 \
  --target-class 0 \
  --num-classes 1000 \
  --episodes 40000 \
  --alpha 0.0 \
  --num-images 1000 \
  --top-k 10 \
  --output-dir attack_results
```

### 3. ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

```bash
# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ
python example_rlb_mi.py
```

## ğŸ”§ ê³ ê¸‰ ì‚¬ìš©ë²•

### íŠ¹ì • GPU ì„ íƒ

```bash
# GPU 0ë²ˆë§Œ ì‚¬ìš©
docker run -it --rm \
  --gpus '"device=0"' \
  -v $(pwd)/checkpoints:/app/checkpoints \
  rlb-mi:gpu bash

# GPU 0, 1ë²ˆ ì‚¬ìš©
docker run -it --rm \
  --gpus '"device=0,1"' \
  -v $(pwd)/checkpoints:/app/checkpoints \
  rlb-mi:gpu bash
```

### ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰

```bash
# ì»¨í…Œì´ë„ˆë¥¼ ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹¤í–‰
docker run -d \
  --name rlb-mi-attack \
  --gpus all \
  -v $(pwd)/checkpoints:/app/checkpoints \
  -v $(pwd)/attack_results:/app/attack_results \
  rlb-mi:gpu \
  python main.py run-rlb-mi-attack \
    --generator checkpoints/generator_last.pt \
    --target-model checkpoints/vgg16_celeba_best.pt \
    --target-class 0 \
    --episodes 40000

# ë¡œê·¸ í™•ì¸
docker logs -f rlb-mi-attack

# ì¢…ë£Œ í›„ ê²°ê³¼ í™•ì¸
ls -la attack_results/
```

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
docker run -it --rm \
  -e CUDA_VISIBLE_DEVICES=0 \
  -e PYTHONUNBUFFERED=1 \
  --gpus all \
  rlb-mi:gpu bash
```

## ğŸ“Š ë³¼ë¥¨ ë§ˆìš´íŠ¸ ì„¤ëª…

| í˜¸ìŠ¤íŠ¸ ê²½ë¡œ | ì»¨í…Œì´ë„ˆ ê²½ë¡œ | ì„¤ëª… |
|----------|------------|------|
| `./checkpoints` | `/app/checkpoints` | í•™ìŠµëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ |
| `./attack_results` | `/app/attack_results` | ê³µê²© ê²°ê³¼ (ì´ë¯¸ì§€, agent) |
| `./dataset` | `/app/dataset` | ë°ì´í„°ì…‹ (ì„ íƒì‚¬í•­) |
| `./pretrained` | `/app/pretrained` | ì‚¬ì „í•™ìŠµ ëª¨ë¸ (ì„ íƒì‚¬í•­) |

## ğŸ› ï¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### GPUê°€ ì¸ì‹ë˜ì§€ ì•Šì„ ë•Œ

```bash
# NVIDIA Container Toolkit ì„¤ì¹˜ í™•ì¸
docker run --rm --gpus all nvidia/cuda:12.4.0-base-ubuntu22.04 nvidia-smi

# ìœ„ ëª…ë ¹ì´ ì‹¤íŒ¨í•˜ë©´ NVIDIA Container Toolkit ì¬ì„¤ì¹˜ í•„ìš”
```

### ë©”ëª¨ë¦¬ ë¶€ì¡± ì—ëŸ¬

```bash
# Docker ë©”ëª¨ë¦¬ ì œí•œ ëŠ˜ë¦¬ê¸° (16GB ì˜ˆì‹œ)
docker run -it --rm \
  --memory=16g \
  --gpus all \
  rlb-mi:gpu bash
```

### ê¶Œí•œ ë¬¸ì œ

```bash
# í˜¸ìŠ¤íŠ¸ì™€ ë™ì¼í•œ UID/GIDë¡œ ì‹¤í–‰
docker run -it --rm \
  -u $(id -u):$(id -g) \
  -v $(pwd)/checkpoints:/app/checkpoints \
  rlb-mi:cpu bash
```

## ğŸ§¹ ì •ë¦¬

### ì»¨í…Œì´ë„ˆ ì¤‘ì§€ ë° ì‚­ì œ

```bash
# Docker Compose ì‚¬ìš© ì‹œ
docker-compose --profile cpu down
docker-compose --profile gpu down

# ì§ì ‘ ì‹¤í–‰ ì‹œ
docker stop rlb-mi-attack
docker rm rlb-mi-attack
```

### ì´ë¯¸ì§€ ì‚­ì œ

```bash
docker rmi rlb-mi:cpu
docker rmi rlb-mi:gpu
```

### ì „ì²´ ì •ë¦¬ (ì£¼ì˜: ëª¨ë“  Docker ë¦¬ì†ŒìŠ¤ ì‚­ì œ)

```bash
# ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì»¨í…Œì´ë„ˆ, ì´ë¯¸ì§€, ë³¼ë¥¨ ì‚­ì œ
docker system prune -a
```

## ğŸ“ ìœ ìš©í•œ ëª…ë ¹ì–´

```bash
# ì‹¤í–‰ ì¤‘ì¸ ì»¨í…Œì´ë„ˆ í™•ì¸
docker ps

# ëª¨ë“  ì»¨í…Œì´ë„ˆ í™•ì¸
docker ps -a

# ì´ë¯¸ì§€ ëª©ë¡ í™•ì¸
docker images

# ì»¨í…Œì´ë„ˆ ë¡œê·¸ í™•ì¸
docker logs <container_name>

# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ íŒŒì¼ ë³µì‚¬
docker cp <container_name>:/app/attack_results ./local_results

# ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
docker stats
```

## ğŸ¯ ì™„ì „í•œ ì˜ˆì‹œ ì›Œí¬í”Œë¡œìš°

```bash
# 1. ì´ë¯¸ì§€ ë¹Œë“œ
docker-compose --profile gpu build

# 2. ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ë° ì ‘ì†
docker-compose --profile gpu run --rm rlb-mi-gpu bash

# 3. ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ ê³µê²© ì‹¤í–‰
python main.py run-rlb-mi-attack \
  --generator checkpoints/generator_last.pt \
  --target-model checkpoints/vgg16_celeba_best.pt \
  --target-class 0 \
  --episodes 40000

# 4. ê²°ê³¼ í™•ì¸ (í˜¸ìŠ¤íŠ¸ì—ì„œ)
# exitë¡œ ì»¨í…Œì´ë„ˆ ì¢…ë£Œ í›„
ls -la attack_results/
```

## ğŸ”— ì°¸ê³  ìë£Œ

- [Docker ê³µì‹ ë¬¸ì„œ](https://docs.docker.com/)
- [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)
- [Docker Compose ë¬¸ì„œ](https://docs.docker.com/compose/)
